
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Samiha Mirza</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <div class="container">

    <header>
      <h1>Samiha Mirza</h1>
      <p class="subtitle">
        PhD Candidate in Computer Science · Applied Machine Learning · Data-Centric AI
      </p>
      <p class="links">
        <a href="mailto:samiha.mirza1234@gmail.com">Email</a> ·
        <a href="https://www.linkedin.com/in/samiha-mirza-a437b2160">LinkedIn</a> ·
        <a href="https://scholar.google.com/citations?user=R1Iy2mAAAAAJ&hl=en&oi=ao">Scholar</a> ·
        <a href="Samiha_2026_Resume_T.pdf">CV</a>
      </p>
    </header>

    <section>
      <h2>About Me</h2>
      <p>
        I am a PhD candidate in Computer Science at the <a href="https://www.uh.edu/">University of Houston</a>, advised by <a href="https://shishirkshah.github.io/">Dr. Shihsir Shah</a> working at the
        intersection of applied machine learning, representation learning, and robustness
        for real-world, high-variability datasets.
      </p>
      <p>
        My research focuses on <b>data-centric AI</b>: understanding how data quality,
        distribution shift, and structural variability influence model behavior. I design
        experimental frameworks and learning strategies that improve generalization,
        stability, and interpretability of deep learning systems, particularly for
        imaging and perception problems.
      </p>
      <p>
        I have industry research experience at <a href="https://www.shell.us/">Shell</a>, where I built end-to-end ML pipelines,
        conducted controlled experiments, and translated model outputs into actionable
        decision-support tools.
      </p>
    </section>

    <section>
      <h2>Education</h2>
      <ul>
        <li>
          <b>PhD in Computer Science</b>, University of Houston <br>
          <span class="muted">Aug 2022 – May 2026 (expected)</span>
        </li>
        <li>
          <b>MS in Computer Science</b>, University of Houston <br>
          <span class="muted">June 2025</span>
        </li>
      </ul>
    </section>

    <section>
  <h2>Selected Projects</h2>

  <!-- Project 1: Continual Learning / KD -->
  <div class="project-row">
    <div class="project-media">
      <img src="assets/KD_Paper_images-Overall_architecture.jpg" alt="Knowledge distillation teacher-student framework">
    </div>
    <div class="project-text">
      <h3>Continual Learning and Domain Adaptation via Knowledge Distillation for Robust Segmentation</h3>
      <p>
        This work investigates continual learning strategies for segmentation under realistic data distribution shift,
        where models are incrementally updated with new data distributions to mitigate catastrophic forgetting.
       A teacher–student distillation framework is proposed where prior model guides optimization of a student
        during later stages via a weighted loss. Ongoing work is focusing on utilizing CycleGANs to achieve domain adaptation
      </p>
      <p class="project-links">
  <a href="https://www.springerprofessional.de/en/recall-based-knowledge-distillation-for-data-distribution-based-/50272374">paper</a> ·
</p>
      <!-- Optional links -->
      <!-- <p class="project-links"><a href="#">Paper</a> · <a href="#">Code</a></p> -->
    </div>
  </div>

  <!-- Project 2: Autoencoder -->
  <div class="project-row">
    <div class="project-media">
      <img src="assets/overall_pipeline.jpg" alt="Autoencoder latent space pipeline">
    </div>
    <div class="project-text">
      <h3>Autoencoder-Based Generative Latent Space Analysis for Data Selection</h3>
      <p>
        To achieve domain generalization while developing segmentation models, we train autoencoders to learn compact latent embeddings that capture dominant structural and textural patterns,
        and then use the encoder as a fixed feature extractor to project samples into a shared latent space.
        Generative latent-space structure is analyzed to identify outliers and underrepresented modes. A lightweight classifier
        (e.g., SVM) supports principled selection of informative samples for downstream segmentation, improving robustness
        under variability.
      </p>
      <p class="project-links">
  <a href="">Paper</a> ·
</p>
    </div>
  </div>

  <!-- Project 3: EAGE / Data selection -->
  <div class="project-row">
    <div class="project-media">
      <img src="assets/frequency_based.jpg" alt="Feature learning + SVM data selection">
    </div>
    <div class="project-text">
      <h3>Data-Centric Quality Assessment for Robust Seismic Interpretation Models</h3>
      <p>
        This work studies how seismic data quality and label quality influence salt boundary segmentation under domain
        shift. We evaluate human-defined quality metrics and model-driven feature representations, and analyze their relationship
        to segmentation accuracy across datasets. Quality-aware data selection is integrated into the training workflow to improve robustness when generalizing to
        unseen domains, highlighting dataset curation as a first-class design choice in seismic interpretation pipelines.
      </p>
      <p class="project-links">
  <a href="https://www.earthdoc.org/content/papers/10.3997/2214-4609.2025101452">Paper1</a>
  <a href="https://www.scitepress.org/Papers/2025/131664/131664.pdf">Paper2</a>
</p>
    </div>
  </div>

</section>

<footer>
      <p class="muted">
        © 2026 Samiha Mirza · Built with HTML & GitHub Pages
      </p>
    </footer>

  </div>
</body>
</html>